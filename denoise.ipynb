{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99153f9e-509c-4887-956c-76eb31e487bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/ytsum/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/harry/ytsum/.venv/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/harry/ytsum/.venv/lib/python3.10/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "from denoiser import pretrained\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "import whisperx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1527b6-890e-4ac2-90ae-9523f17928b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser =  pretrained.dns64().cpu().eval()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def denoise(audio_file, sr=None):\n",
    "    global denoiser\n",
    "    if type(audio_file) is str: \n",
    "        audio, sr = torchaudio.load(audio_file)\n",
    "    else:\n",
    "        audio = audio_file\n",
    "        assert sr is not None, \"You must provide sample rate for loaded audio\"\n",
    "    \n",
    "    audio = audio.sum(dim=0, keepdim=True)\n",
    "    audio = Resample(sr, denoiser.sample_rate)(audio)\n",
    "    B = 40\n",
    "    denoiser = denoiser.cuda()\n",
    "    wav = audio.split(B*denoiser.sample_rate, dim=1)\n",
    "    denoised = []\n",
    "    for w in wav:\n",
    "        denoised.append(denoiser(w.cuda()))\n",
    "    denoiser = denoiser.cpu()\n",
    "    denoised = torch.cat(denoised, dim=-1)\n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca636df-479d-4dca-b721-0b9856cde49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs = denoise(\"/home/harry/abs.opus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c32eeaa-14e5-474c-8b91-d12f25b601bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.2+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "from denoiser import pretrained\n",
    "denoiser =  pretrained.dns64().cpu().eval()\n",
    "\n",
    "device = \"cuda\" \n",
    "batch_size = 16\n",
    "compute_type = \"float16\"\n",
    "whisper = whisperx.load_model(\"large-v3\", \"cuda\", compute_type=compute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4fbe246-4ed8-4750-bfbb-b11f4bac7837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en (0.99) in first 30s of audio...\n",
      "number of words 4074\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def transcribe(audio):\n",
    "    global whisper\n",
    "    result = whisper.transcribe(audio.cpu().numpy(), batch_size=batch_size)\n",
    "    alltext = \"\"\n",
    "\n",
    "    for s in result[\"segments\"]:\n",
    "        alltext += s[\"text\"]\n",
    "        \n",
    "    print(\"number of words\", len(alltext.split(\" \")))\n",
    "    return result\n",
    "\n",
    "results = transcribe(abs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc94c28-6e10-4cad-8ba7-701ebd5b0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:31<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "                                           \n",
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\")\n",
    "\n",
    "# text = \"Hello my name is\"\n",
    "# + inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7453f9-e410-458c-8e57-b3a92b2dfe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prompt=\"\"\"\n",
    "You will receive chunks of a transcript. You won't know who is saying what but should summarise the point that are made.\n",
    "\n",
    "Points:\n",
    "\n",
    "Brian Johnson is spending $2m a year to stay young\n",
    "Using algorithmic precision\n",
    "In peak performance of entire life\n",
    "Extended my lifespan over 30%\n",
    "Reduced age by 12 years\n",
    "Increased muscle and strength\n",
    "Six months of perfect sleep\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt=\"\"\"\n",
    "\n",
    "Transcript Title: Abraham Voice Note\n",
    "\n",
    "Transcript Content:\n",
    "\n",
    "{transcript}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "final_prompt=\"\"\"\n",
    "You've produced this list of points from a podcast transcript:\n",
    "\n",
    "Points:\n",
    "\n",
    "{points}\n",
    "\n",
    "Remove duplicated and produce a paragraph summary of the points.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd58dd0-f8e5-474b-bfde-86f598075f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(pre_prompt:str, prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": pre_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Ok great I'll start extracting points from content using this template\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "    # model_inputs = tokenize(encodeds, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(encodeds, max_new_tokens=200, do_sample=True)\n",
    "    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89bf2af4-6d2b-4fbb-a2e7-702f43914902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "segments = [s[\"text\"] for s in results[\"segments\"]]\n",
    "all_text = \"\\n\".join(segments)\n",
    "result = re.split(r'[.?!…]+', all_text)\n",
    "idxs = [m.start() for m in re.finditer(r'[.!?]', all_text)]\n",
    "pidx = [0] + [idx + 1 for idx in idxs]  # +1 to start the next sentence after the punctuation\n",
    "sentences_per_chunk = 10\n",
    "\n",
    "chunks = []\n",
    "for i in range(0, len(pidx), sentences_per_chunk):\n",
    "    chunks.append(\"\".join(all_text[pidx[j]:pidx[j+1]] for j in range(i, min(i+sentences_per_chunk, len(pidx)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31220420-10a8-4f00-ad60-45ab2f535242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey Ari, just listening to the update. Apologies I wasn't here yesterday, but I really appreciate it, man. I appreciate you pushing forward with it as well. So completely followed what you were saying there. That was really nice, actually. Thank you so much for the... It was actually really nice and succinct. I completely understood where the problem was coming from.\n",
      "Points:\n",
      "\n",
      "* Abraham wasn't present but listened to the update later\n",
      "* Appreciates Ari for pushing forward\n",
      "* Understood the problem Ari was discussing\n",
      "* Thankful for the update and found it succinct.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " So thank you for explaining the problem space that you're trying to deal with there.\n",
      " And the idea that you can generate the TTS, like TTS has gone so good, especially with the stuff that you're working on, that you're able to sort of generate it and then use it as the data sets themselves and then avoid the labeling and learning problem quite easily because you're the one that's generating the data and then getting it to self-label. As far as I understand, right, that sounds like it would be a really, really good way to be able to\n",
      " uh to get a much much more thoroughly trained model out there and then apply it to real world data and see how it handles it because honestly from the stuff that you send me like\n",
      " If you're able to generate that with, I don't know, let's say even 100 voices, 100 different voices, 100 different speech patterns with 100 different intonations and 100 different scenarios, like you were saying, like football commentary and stuff like that, all the different wild intonations and cadences that all these different professions and speech styles and use cases go for and have to use and end up using in the real world, that...\n",
      " sounds like it would be that that sounds like it would be a really a viable way of actually being able to test i mean like i i'm with you i'm following your hypothesis here like it sounds like something that if you weren't able to able to train it and then i'm able to apply to the real world data you'd be able to actually get some incredibly decent um some decent results hopefully right otherwise we wouldn't we wouldn't really bother trying it like there was only one way to find out right which was to generate that data and then to to retrain it\n",
      " It sucks that you'd have to retrain your model. So, you know, like you said, there's a few steps in between that would block this, that you'd have to sort of retrain it because you don't want to use what you produced. So that's a bit of a shame. But no, it's really interesting. I was having a look at a couple of other options on my side.\n",
      "Points:\n",
      "\n",
      "* The TTS (text-to-speech) system being developed can generate data and self-label\n",
      "* This method can result in a more thoroughly trained model\n",
      "* The model can be applied to real-world data to see how it handles\n",
      "* The system can generate different voices, speech patterns, intonations, and scenarios\n",
      "* This method can help test the hypothesis and potentially yield decent results\n",
      "* Retraining of the model is necessary, which is time-consuming and not ideal.\n",
      "\n",
      "Note: The points above is an extract from the given transcript where the speaker (Abraham) explained the concept of generating and self-labeling data of a TTS system and the potential benefits and challenges of using this method.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I saw just a few other ideas that we could kind of play around with. And I'm still trying to kind of put it into notion, but it's basically like trying to come up with essentially the latest...\n",
      " the easiest possible idea that we can work with, leveraging some of the expertise that we've put together, right? Because we've got your side really having focused on TTS models and that realm of technology. And then we've also got, on my end, I've got...\n",
      " Over the last couple of years, I've worked a lot with the ability to basically roll out certain strategies to users and being able to get the idea.\n",
      "Points:\n",
      "\n",
      "* Abraham had a few ideas to play around with\n",
      "* Trying to come up with the easiest possible idea using leveraged expertise\n",
      "* Abraham has experience with rolling out strategies to users\n",
      "* Expertise on TTS (Text-to-Speech) models on the other side.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm trying to basically condense in town to what we've done from a Web3 perspective down into a lot of stuff that I can now look at and be like, hey, you know what?\n",
      " there is something very, very easy about just what users are currently looking for. There's an intersection, right, between what users are you looking for and it's usually just about\n",
      " If you boil it down to the simplest point, Harry, it's literally like you just want something that can make their life simpler, that is worth the money that they're paying. That's the most obvious statement you can make. But it's actually simpler than that because ultimately what users are currently looking for is solutions that are just hyper-optimizing their time and hyper-optimizing the value that they're getting out of it.\n",
      " solutions that are basically just stream absolutely streamlining the things that they're already doing and that's why and that's why i see like huge impact being done without really having to reinvent the wheel right because like because that's what the advent of ai is doing like\n",
      " And I go back to this point, because I think I said this to you when we met up, but when we had the dot-com bubble and we had the advent of the World Wide Web, especially the interactive World Wide Web, right? The first iteration of the World Wide Web was not interactive. It was a static website. People could not interact back with it.\n",
      " Right.\n",
      "Points:\n",
      "\n",
      "* Trying to condense what they've done from a Web3 perspective\n",
      "* Users are looking for solutions that can make their life simpler\n",
      "* Solutions that hyper-optimize users' time and value they're getting\n",
      "* These solutions streamline things users are already doing\n",
      "* No need to reinvent the wheel as AI is already doing this\n",
      "* Mention of the dot-com bubble and the advent of the interactive World Wide Web\n",
      "* First iteration of the World Wide Web was not interactive, it was static.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And then we had the interactive web, which then gave birth to social media, e-commerce and all the other things that we now take for granted. But even just social media and e-commerce were huge leaps in what we were already able to do. We were already able to sort of talk to each other and even long distance communication. But social media made these, you know, and we had forums.\n",
      " right but social media created made made them a hell of a lot more interactive a hell of a lot more convenient a hell of a lot more streamlined that was the revolution that was the the the common revolution really was about like being able to bring people together being able to actually just take everything that they were already doing and just doing it like without even them realizing that's kind of what they in the case of social media for instance that wasn't even really what they wanted but nowadays\n",
      " The things that people are focusing on with any of these new technologies, and it was sort of the same thing when we were kind of working in the Web3 space, was when we were talking about Web3, which is, okay, well, Web2 is all about extracting data out of you, and you are the product, ultimately, right? The individual became the product in every one of these cases, where their data became\n",
      " became taken away like they they were data producers ultimately in an age that only cared about that became so data driven that that's all it ever cared about right and so\n",
      " Web2 is typically categorized by the exploitation of people's data. It's typically categorized by the idea that people are being harnessed for all the information that they have. People are being harnessed. Value is being extracted from people, which is why they get these products for free, which is why they get YouTube, Facebook, Instagram, etc. for free, because their data is being harnessed.\n",
      "Points:\n",
      "\n",
      "* Interactive web gave birth to social media and e-commerce\n",
      "* Social media made communication more interactive, convenient, and streamlined\n",
      "* Web3 is about individuals becoming data producers\n",
      "* Web2 is categorized by exploitation of people's data\n",
      "* People are harnessed for information they have\n",
      "* Value is extracted from people in Web2\n",
      "* People get free products like YouTube, Facebook, Instagram in exchange for their data in Web2\n",
      "* Web3 aims to change this exploitative relationship between platforms and users\n",
      "\n",
      "(Note: The speaker doesn't explicitly mention Web3 in the transcript as a solution, but it can be inferred from the context that Web3 aims to change the exploitative relationship between platforms and users.)\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " They are being harnessed as users. And so the revolution, the supposed revolution, which we're not quite there yet with...\n",
      " uh i don't think we're going to be there for another couple of years with web3 is that now you don't get like the data becomes anonymous you get to be in control of the data that you want to give out right you tend to you you are able to then get back your uh the value that you're creating ultimately so that that idea like\n",
      " when we had it, we were like, okay, great, now let's just apply that to the absolute basic principle of users want something that can make their lives easier, users want something that can derive more value out of, and that can make their life easier, that can optimize their life, that can streamline their life, and the issue became that, actually, okay, well, with Web3, you can make them make money, that was kind of one of the first big movements, where they were like, okay, let them generate money for what they were able to do, um,\n",
      " what they're able to do with their data. Because if they have full ownership of their data, they should now be able to sell, they should now have control over how they basically distribute that data, which means they should have control over how they sell that data to consumers out there. Sorry, to agents of companies, the people that are going to consume that data, marketing solutions, advertising, etc. That's the problem.\n",
      " I mean, the idea was great, right? Like, hey, why not take back ownership of your data and then sell it to the people that want it?\n",
      "Points:\n",
      "\n",
      "* Web3 aims to harness users with anonymous data control\n",
      "* Users want ways to make their lives easier and optimize their lives\n",
      "* Web3 first big movement was letting users generate money from their activities\n",
      "* With full ownership of their data, users can control and sell data to companies\n",
      "* Companies can use this data for marketing solutions and advertising\n",
      "* The idea of Web3 is to take back ownership of user's own data and sell it.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You have control over how that data is being generated. You have control over how that data is being distributed. You're in control of all of these things.\n",
      " It's a long-winded rant. I promise this is going to look back to AI. I promise. Because my point is, the whole... This is kind of the stream of thought that I've been having for the last couple of days.\n",
      "Points:\n",
      "\n",
      "* Individual has control over generation and distribution of their data\n",
      "* Thought process related to AI has been ongoing for a few days.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The whole point was that... I think the reason that it didn't work was because the whole underlying point of it was not to actually make their lives any easier. The problem...\n",
      " The problem became that it was actually getting so complicated to use. Yes, it was giving them back value. It was giving them back more value than ever before, but it was not making their lives easier to use.\n",
      "Points:\n",
      "\n",
      "* The underlying point of something was not to make lives easier\n",
      "* It became complicated to use\n",
      "* Giving back more value but not making it easier to use\n",
      "\n",
      "(Note: The first line is a bit confusing as it refers to \"the whole point\" and \"the whole underlying point\" but I assumed that they are the same.)\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streaming services only worked because they were making people's lives easier to use. We stopped using...\n",
      " all those dodgy, like, LimeWire, Napster, all those websites shut, like, we stopped using them because they became, like, increasingly difficult to use, in the sense that, like, oh, you had to continuously, you know, fight with viruses and malware, you didn't always have immediate, you didn't always have immediate availability for, to the data, to the information that you wanted, to the PD that you wanted, and then, you know,\n",
      " iTunes kind of, like, iTunes lost out to Spotify massively during that time before they obviously called their own streaming service because people were like, oh, perceived value. It just always comes down to perceived value. Like, Spotify's model works because of perceived value. You don't own a single song on Spotify, but you have access to every song, right? And you do so for, like, £10. So the idea of the human brain is, oh, I'm able to interact with a million, million, million songs or whatever.\n",
      "Points:\n",
      "\n",
      "* People stopped using illegal streaming services as they became difficult to use\n",
      "* Users had to deal with viruses and malware\n",
      "* Availability of data and information was not immediate\n",
      "* iTunes lost out to Spotify due to perceived value\n",
      "* Users don't own any song on Spotify but have access to every song\n",
      "* Spotify's model works because of the perceived value\n",
      "* Humans perceive value in having access to a large library of songs for £10\n",
      "\n",
      "I hope this is helpful! Let me know if you need anything else edited or formatted.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You know, I...\n",
      " I paid £4.85 versus what a single album for me to own a single album which has a total of 10 tracks on it for me to own a single album that has 10 tracks on it I have to pay a tenner and then I but and and so and then so the same thing happened with Netflix right like you don't own a single movie but you own all of these movies it's convenient steam killed\n",
      " not killed but like was only able to go up against the rampant piracy on pc right because pc wasn't was it was not a closed loop system it wasn't like the playstation 4 and the through the playstations and the xboxes and the nintendos because\n",
      " All of those systems were so much harder to pirate on. All those systems required you to, like, you know, crack them first and kind of do some dodgy bullshit on them. And so, basically, the barrier to entry was really difficult. And then the convenience to do it was really, really difficult. Steam was so easy. And it's still, you know, so, so easy.\n",
      "Points:\n",
      "\n",
      "* Had to pay £4.85 for a single album with 10 tracks\n",
      "* To own a single movie on Netflix costs the same as owning all movies\n",
      "* Steam was able to compete with rampant piracy on PC\n",
      "* PC was a non-closed loop system, easier to pirate on\n",
      "* Other systems like Playstation 4, Xbox, Nintendo are harder to pirate on\n",
      "* Had to crack these systems first and do some \"dodgy bullshit\"\n",
      "* Steam's barrier to entry for piracy is high and it is very convenient to use.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I mean, the only problem was that you had to sort of download all of these files from, like, torrent websites and stuff like that, sure. But it was much, much easier than on the other machines, obviously. Now, why Steam ended up working?\n",
      " Oh, the only reason that Steam ended up working was because Gabe made it cheaper, right? The head of Steam basically made it cheaper for them. So cheap for them. Like, make it so affordable, make it so enticing to buy these games that the convenience of clicking on a £2 game, on a £1 game, on a £3 game beats, right? Beats the hassle of having to go to, you know, a torrenting website and downloading the...\n",
      "Points:\n",
      "\n",
      "* Had to download files from torrent websites\n",
      "* Steam ended up working because made cheaper by Gabe (head of Steam)\n",
      "* Games on Steam are cheap, affordable and enticing to buy\n",
      "* Convenience of buying games on Steam beats hassle of downloading from torrent websites.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " the game and then patching it and cracking it and all the rest of it that used to be involved with it. And that's why Steam basically was able to go up against one of the biggest problems. I mean, you have to understand the piracy problem was such a huge problem at the time that developers literally just wanted to stop developing for PC. It became underdeveloped. People stopped developing and releasing things for PC. Now fast forward to today and we have Xbox has fully\n",
      " has fully done release cycles to be on PC and Xbox together now, so all of their exclusives are now coming on PC, and PlayStation is starting to release their old exclusives on PC. I would not have imagined that world ever happening in a million trillion years because of the reputation that PC had. Why did it happen? Because of convenience. Because the perceived value was easier.\n",
      "Points:\n",
      "\n",
      "* Piracy was a huge problem for game developers on PC in the past\n",
      "* Steam helped solve the piracy problem\n",
      "* Developers had stopped developing and releasing games for PC due to piracy\n",
      "* PC gaming has become more convenient and has higher perceived value now\n",
      "* Xbox and PlayStation are releasing exclusives on PC as well now.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Okay, so now I've rambled on about that point forever.\n",
      " That is what AI is going to allow us to do, ultimately, right? Which is this idea that you can simplify, you can make everything more convenient for them, and it doesn't have to reinvent the wheel, because Steam did not reinvent the wheel by selling PC games at a cheaper price. Spotify did not reinvent the music industry, almost did, technically, sure, with streaming services, but streaming services were kind of around at that point anyway, right?\n",
      " No, but what Spotify did was like, hey, here's the perceived value. It's through the roof, right? iTunes was already a digital music distribution service. Spotify came around and was like, hey, this is the same distribution service, but it's subscription-based. So you don't own a single one of these. But it was just easier.\n",
      "Points:\n",
      "\n",
      "* AI will simplify and make things more convenient\n",
      "* Steam did not reinvent the wheel, but offered PC games at cheaper price\n",
      "* Spotify did not reinvent music industry, but changed perception of value with subscription-based service\n",
      "* Spotify's service was easier to use and did not require ownership of music.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It was more convenient. I can now just, instead of having to purchase all these various albums for huge prices, even though I don't own any of it now, I can just listen to everything. So I don't own anything, but I can listen to everything. That's great.\n",
      " You know, that's, that's convenience. That is ultimate. It ultimately is convenience. So the idea is like the app that I was telling you, right? That next step to do app, right? The reason that I think it's something that has legs to work on is because literally all it does is it's a wrapper around the prompts.\n",
      "Points:\n",
      "\n",
      "* Abraham can now listen to everything through a convenient app\n",
      "* He doesn't own any albums but can access them through the app\n",
      "* He thinks the app has potential because it acts as a wrapper around prompts.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's literally a prompt wrapper, but more, more than that, it simplifies the process of having to track these things for you. Like if I go, if I go into any of these elements and I type, you know, whatever, and I type in my goals, if I want to do all of that stuff and I want to like, you know,\n",
      " jump into it and I go, okay, what am I actually doing? All I'm doing is I'm interacting, I'm interacting with the wrapper. If this app, all of the alarm systems interact with the wrapper around what ChatGPT would do, but I'm able to get, here's the crucial bit, the data that I'm able to get out of it, the data that I'm able to extract out of the, um,\n",
      " out of the answer that the LLM is going to give me, I'm able to take that and I'm able to do things with it that are more convenient for them, such as notifications. ChatGPT can't give you notifications. LLM answers fundamentally can't give you a single anything because they're just answers. And you're the one that has to do the work with that answer.\n",
      " But if you're able to basically take the output of an LLM and then do something with it so as to make it so much more convenient for the user, that is, I honestly think, where the next wave of like quick\n",
      " quick iterations of companies will come from and that's and that's where in all honesty that's where you're going to generate a hell of a hell of a lot of revenue initially because that's super super easy to do right the majority of that development is then focused on like optimizing yeah sure like optimizing our own 11 for it to make it nicely affordable etc like cheaper cost efficient for us to run but\n",
      " uh a lot of that is just also just web 2 development because we're then taking the output of an lm and then we're wrapping it in in in features essentially we're taking we're taking the output of it and we're giving those features back to the user and rather we're giving the output back to the user in a better in in a format and in an interactive in an interactive medium that is more\n",
      " that is more efficient for the user, that is easier for the user, that is more convenient for the user, that just makes their lives easier. That's the bottom line. If you can make their life easier.\n",
      "Points:\n",
      "\n",
      "* The content is discussing a \"prompt wrapper\" that simplifies the process of tracking and interacting with large language models (LLMs), such as ChatGPT\n",
      "* The wrapper allows the user to easily view and extract data from the LLM's answers\n",
      "* The user can then do more with the answer, such as setting notifications, which is not possible through LLMs alone\n",
      "* Majority of development is focused on optimizing the wrapper's performance and efficiency\n",
      "* The wrapper's output is then given back to the user in a more convenient and interactive format, making the user's life easier.\n",
      "\n",
      "Note: In this text, the speaker is using the term \"wrapper\" as an abstract concept, but in programming, a wrapper is a type of software that provides a simplified interface to an existing application or system, allowing users to interact with the application or system in a more convenient way.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And so think about the opportunity space that that provides, because that's a huge opportunity space. So even though we have like, so for instance, you have TTS as an idea, but TTS is a little bit inaccessible nowadays. Good TTS is a bit inaccessible, even though you can see how frequently it's being used everywhere. Like every YouTube video now,\n",
      " Not every YouTube video, but a lot of new channels are popping up, and all they're doing is just putting TTS in. A lot of TikToks and social media, all they're doing is just using that crappy text-to-speech voices that they're using. These are the same old, outdated voices that don't sound legit whatsoever. So even if you took your TTS model, and you just provided it to the end user as a way of basically being able to slap it on top of videos,\n",
      " You're not reinventing the wheel, that's already been done, but you're just optimizing it, you're creating a better TTS. And they could do that, right? They could go to some cracked TTS AI out there and type in what they wanted, get the output as an MP3 format, and then put it on top of a video. But most of them don't know how to access that.\n",
      "Points:\n",
      "\n",
      "* Opportunity space for TTS (text-to-speech) is large\n",
      "* Good TTS is not very accessible currently\n",
      "* Many YouTube videos and TikToks use text-to-speech voices\n",
      "* Existing text-to-speech voices are outdated and not legitimate\n",
      "* Optimization of TTS can be done by providing a better TTS model as an end user\n",
      "* Most end users may not know how to access cracked TTS AI\n",
      "* End users can type in what they want, get output as MP3 format, and put it on top of a video\n",
      "\n",
      "(Note: TTS means text-to-speech)\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm telling you now, most of them have no idea how to access that yet.\n",
      " Right? We're still a year to two years away from that even being remotely viable for most people. Most people are just content creators. They just wanted content create. So if you can wrap it in a content creation solution, and I'm not saying like, you know, add all the bells and whistles to it, but just something simple that is just literally in an app format that literally just creates realistic AI voices for a cheap price or whatever. Like, oh yeah, hell yeah. That sounds amazing. And then you just tweak it a bit more to be kind of like content creatively focusing. Like, hey,\n",
      " can immediately import this on top of that or whatever or hey you can you can get ai to train on your voice like you know like let's say you're a youtube content creator that's got hundreds of videos on his channel and he's just sick and he just wants to pump out videos faster so you have ai train on their on their voice sets like that's that's a solution that you can start to create this overnight\n",
      " because i'm sure some of them would try it if they believe that it would work right if you could prove that it sounds almost as good as the real person uh people would want to pump out people want to pump out content faster people want to be able to and and one of the biggest some of the biggest hurdles to content creation has been assets which now ai is tearing apart with all the arts that ai generated art that's out there you know like we're getting loads and loads and loads and loads of assets out there that are being that are being published\n",
      " just through AI art.\n",
      "Points:\n",
      "\n",
      "* Most people are just content creators\n",
      "* Looking for simple AI voice creation solution\n",
      "* Cheap price for AI voice creation\n",
      "* Tweak the AI for content creation focus\n",
      "* Importing content easily on top of AI voice\n",
      "* AI training on specific voice sets\n",
      "* Content creators want to pump out content faster\n",
      "* AI tearing down barriers in content creation\n",
      "* AI generated art becoming popular\n",
      "\n",
      "(Note: The points may not be grammatically correct, but they capture the essential ideas presented in the transcript.)\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And the second thing is like voiceovers and doing everything else that they need to do, right? Like the voiceovers on these videos and everything else that they want to do with them. So like, why not be able to just focus on that?\n",
      " why why not why not be able to just take basically what's already there and then just optimize it because you have a you have a good version of it you're able to then stick it into a like wrap it up in a nice and neat tidier package that's just so much more convenient for these users um or hyper tailored to these users because that's what it is discord it's just a hyper tailored solution\n",
      " It's just another chat forum. It's like Slack or whatever, but it was just hyper-focused for gamers. And so it took over the market. The moment that something is hyper-focused for a group of people, it's also hyper-convenient for that group of people. It solves all of their problems for those sets of people.\n",
      " Like the Opera GX browser, the only way that the Opera GX browser is able to compete in the market of Chrome and Firefox and everything else, the only way that it can compete is because it's hyper-focused for gamers, as an example, right? So then gamers download it.\n",
      "Points:\n",
      "\n",
      "* Voiceovers and other tasks can be optimized and improved\n",
      "* Discord is a chat forum hyper-focused on gamers, making it convenient for them\n",
      "* Discord took over the market because of its hyper-focused appeal\n",
      "* Opera GX browser competes by being hyper-focused on gamers\n",
      "* Hyper-focused products solve a group of people's problems, giving it a competitive edge.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why? Because it's got everything that a gamer needs built right into it. It's because you can compete.\n",
      " Anything extra that other browsers can't? No, technology really can't. But it thrives in the gaming community because it's hyper-focused for that shit. Visual Studio Code is just hyper-focused for the new dev experience. It's nice that CleanA works better than whatever the fuck we had before, Sublime Text 2 or the Atom, even the Atom code creator wasn't that bad, right? But like,\n",
      " And that's why this new age is all about hyper-tailoring these solutions, which is actually very, very easy to do because you're not reinventing the wheel any given time. The moment that you don't reinvent the wheel, you're able to pump out these ideas faster.\n",
      "Points:\n",
      "\n",
      "1. Browser specifically built for gaming needs\n",
      "2. Compete better with other browsers\n",
      "3. Hyper-focused for gaming community\n",
      "4. Visual Studio Code is also hyper-focused for new dev experience\n",
      "5. CleanA works better than previous versions like Sublime Text 2 or Atom\n",
      "6. New age is about hyper-tailoring solutions\n",
      "7. Easy to do since not reinventing the wheel\n",
      "8. Pump out ideas faster by not reinventing the wheel.\n",
      "\n",
      "-----\n",
      "\n",
      " I'm going to summarize that rant.\n",
      " and i'm going to send you a shorter voice note because i'm looking at the time now and it's like 19 minutes and i probably wouldn't listen to a 19 minute voice so if you did then you got to this point then you're a legend uh but i'm going to send you a shorter voice note that just summarizes summarizes what i put uh what i said in this as well but yeah i hope that i hope that kind of and then what i'm hoping to do is to just get you kind of like uh\n",
      " just bounce ideas off of you and to just kind of like i don't know like see if any anything that i'm saying is kind of like sparking something within you because you have a much better understanding of the capability of the technology and how easy any any any one part of that is to integrate so if yeah if we're able to sort of kind of go with that line and i think we can i'm sure there's a million things that we can do there for me like it's mind baffling like\n",
      " how many opportunities there should be in this space. But I just kind of need to think about breaking out. The ideas that I mentioned with that content creation TTS stuff is huge. I think if you actually nail that stuff down and you create a hyper-focused, hyper-tailored solution for content creators, you will make loads of money. You will.\n",
      " It would be almost a no-brainer for these content creators to jump on there because of the amount of value that you're creating for them and the amount of time that you're saving for them and how focused it is for what they're doing. Anyway, I'll speak to you soon. Take care.\n",
      "Points:\n",
      "\n",
      "* Speaker will send a shorter voice note summarizing their previous rant\n",
      "* Wants to bounce ideas off the listener and see if any ideas are sparking\n",
      "* Thinks there are many opportunities in technology space\n",
      "* Content creation TTS (text-to-speech) is a huge opportunity\n",
      "* A hyper-focused, hyper-tailored solution for content creators would be valuable and save them time\n",
      "* Believes content creators would be interested in such a solution.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "for c in chunks:\n",
    "    out = generate(pre_prompt, prompt.format(transcript=c))\n",
    "    print(c)\n",
    "    print(out[out.rfind(\"Points:\"):])\n",
    "    print(\"\\n-----\\n\")\n",
    "    points += out[out.rfind(\"Points:\"):].replace(\"\\n\", \"\").split(\"*\")[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6101840-3a4c-4252-84ac-465286baa24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
